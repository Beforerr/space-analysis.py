{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: JUNO Magnetic field data pipeline\n",
    "---\n",
    "\n",
    "JUNO Magnetic field data can be downloaded from [PDS](https://pds-ppi.igpp.ucla.edu/mission/JUNO/JNO/FGM) website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp missions/juno/fgm\n",
    "# | hide\n",
    "# | export\n",
    "import os\n",
    "import polars as pl\n",
    "from zipfile import ZipFile\n",
    "import pooch\n",
    "from pooch.processors import Unzip\n",
    "\n",
    "from pipe import filter\n",
    "from space_analysis.utils.lbl import load_lbl\n",
    "\n",
    "from typing import Literal, Callable\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```txt\n",
    "File Naming Convention                                                        \n",
    "==============================================================================\n",
    "Convention:                                                                   \n",
    "   fgm_jno_LL_CCYYDDDxx_vVV.ext                                               \n",
    "Where:                                                                        \n",
    "   fgm - Fluxgate Magnetometer three character instrument abbreviation        \n",
    "   jno - Juno                                                                 \n",
    "    LL - CODMAC Data level, for example, l3 for level 3                       \n",
    "    CC - The century portion of a date, 20                                    \n",
    "    YY - The year of century portion of a date, 00-99                         \n",
    "   DDD - The day of year, 001-366                                             \n",
    "    xx - Coordinate system of data (se = Solar equatorial, ser = Solar        \n",
    "         equatorial resampled, pc = Planetocentric, ss = Sun-State,           \n",
    "         pl = Payload)                                                        \n",
    "     v - separator to denote Version number                                   \n",
    "    VV - version                                                              \n",
    "   ext - file extension (sts = Standard Time Series (ASCII) file, lbl = Label \n",
    "         file)                                                                \n",
    "Example:                                                                      \n",
    "   fgm_jno_l3_2014055se_v00.sts    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | code-summary: type definitions\n",
    "# | export\n",
    "JunoPhases = Literal[\"CRUISE\", \"JUPITER\"]\n",
    "JunoFGMCoords = Literal[\"SE\", \"SS\", \"PL\"]\n",
    "JunoFGMTimeResolutions = Literal[\"1SEC\", \"1MIN\", \"FULL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "def unzip_convert_lbl(member: str, fname: str, extract_dir, load_func: Callable, clean=True, fmt=\"arrow\"):\n",
    "    with ZipFile(fname, \"r\") as zip_file:\n",
    "        lbl_fp = zip_file.extract(member, path=extract_dir)\n",
    "        sts_fp = zip_file.extract(member.replace(\".lbl\", \".sts\"), path=extract_dir)\n",
    "\n",
    "        # Convert the file to a different format\n",
    "        df = load_func(lbl_fp).collect()\n",
    "        output_fp = lbl_fp.replace(\"lbl\", fmt)\n",
    "        df.write_ipc(output_fp)\n",
    "\n",
    "        # Remove the lbl and sts files\n",
    "        if clean:\n",
    "            os.remove(lbl_fp)\n",
    "            os.remove(sts_fp)\n",
    "\n",
    "        return output_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def load_jno_lbl(file: str):\n",
    "    df: pl.DataFrame = pl.from_dataframe(load_lbl(file))\n",
    "    return (\n",
    "        df.lazy()\n",
    "        .with_columns(\n",
    "            time=pl.col(\"SAMPLE UTC\").str.slice(0, 4).str.to_datetime(\"%Y\")\n",
    "            + pl.duration(\n",
    "                milliseconds=(pl.col(\"DECIMAL DAY\") - 1) * 24 * 60 * 60 * 1000\n",
    "            )\n",
    "        )\n",
    "        .drop([\"SAMPLE UTC\", \"DECIMAL DAY\", \"INSTRUMENT RANGE\", \"X\", \"Y\", \"Z\"])\n",
    "        .sort(\"time\")\n",
    "    )\n",
    "\n",
    "def unpack_and_convert(fname, extract_dir, process_func=unzip_convert_lbl):\n",
    "    \"\"\"\n",
    "    Post-processing hook to unzip a file and convert it to a different format in real-time. (Otherwise the files unzipped would take up too much space on the user's computer.)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "       Full path of the zipped file in local storage\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with ZipFile(fname, \"r\") as zip_file:\n",
    "        # Extract the data file from within the archive\n",
    "        members = list(zip_file.namelist() | filter(lambda x: x.endswith(\".lbl\")))\n",
    "\n",
    "    func = partial(process_func, fname=fname, extract_dir=extract_dir, load_func=load_jno_lbl)\n",
    "    futures = list(map(func, members))\n",
    "\n",
    "    return futures\n",
    "\n",
    "\n",
    "class UnpackConvert(Unzip):\n",
    "    \n",
    "    old_fmt = \"lbl\"\n",
    "    new_fmt = \"arrow\"\n",
    "\n",
    "    def _extract_file(self, fname, extract_dir):\n",
    "        unpack_and_convert(fname, extract_dir)\n",
    "        \n",
    "    def _all_members(self, fname):\n",
    "        \"\"\"Return all members from a given archive.\"\"\"\n",
    "        with ZipFile(fname, \"r\") as zip_file:\n",
    "            files = zip_file.namelist()\n",
    "            oldfiles = [f for f in files if f.endswith(self.old_fmt)]\n",
    "            return [f.replace(self.old_fmt, self.new_fmt) for f in oldfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "PDS_URL_FMT = \"https://pds-ppi.igpp.ucla.edu/ditdos/download?id=pds://PPI/{dataset}/DATA/{phase}/{coord}/{datatype}\"\n",
    "\n",
    "def download_data(\n",
    "    dataset=\"JNO-SS-3-FGM-CAL-V1.0\",\n",
    "    phase: JunoPhases = \"CRUISE\",\n",
    "    coord: JunoFGMCoords = \"SE\",\n",
    "    datatype: JunoFGMTimeResolutions = \"1SEC\",  # time resolution\n",
    "    processor: Callable = None,\n",
    "    url_fmt=PDS_URL_FMT,\n",
    "    fmt=\"arrow\",\n",
    ") -> list[str]:\n",
    "    \n",
    "    url = url_fmt.format(dataset=dataset, phase=phase, coord=coord, datatype=datatype)\n",
    "\n",
    "    if processor is None:\n",
    "        processor = UnpackConvert()  # default processor, needed to be created here!!!\n",
    "\n",
    "    files = pooch.retrieve(\n",
    "        url=url,\n",
    "        known_hash=None,\n",
    "        progressbar=True,\n",
    "        processor=processor,\n",
    "    )\n",
    "\n",
    "    return sorted(files | filter(lambda x: x.endswith(f\".{fmt}\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(datatype=\"FULL\")\n",
    "# download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev import nbdev_export\n",
    "\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds_dir = \"https://pds-ppi.igpp.ucla.edu/data\"\n",
    "\n",
    "possible_coords = [\"se\", \"ser\", \"pc\", \"ss\", \"pl\"]\n",
    "possible_exts = [\"sts\", \"lbl\"]\n",
    "possible_data_rates = [\"1s\", \"1min\", \"1h\"]\n",
    "\n",
    "juno_ss_config = {\n",
    "    \"DATA_SET_ID\": \"JNO-SS-3-FGM-CAL-V1.0\",\n",
    "    \"FILE_SPECIFICATION_NAME\": \"INDEX/INDEX.LBL\",\n",
    "}\n",
    "\n",
    "juno_j_config = {\n",
    "    \"DATA_SET_ID\": \"JNO-J-3-FGM-CAL-V1.0\",\n",
    "    \"FILE_SPECIFICATION_NAME\": \"INDEX/INDEX.LBL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "import pandas\n",
    "import pdpipe as pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "def process_jno_index(df: pandas.DataFrame):\n",
    "    _index_time_format = \"%Y-%jT%H:%M:%S.%f\"\n",
    "\n",
    "    df.columns = df.columns.str.replace(\" \", \"\")\n",
    "    jno_index_pipeline = pdp.PdPipeline(\n",
    "        [\n",
    "            pdp.ColDrop([\"PRODUCT_ID\", \"CR_DATE\", \"PRODUCT_LABEL_MD5CHECKSUM\"]),\n",
    "            pdp.ApplyByCols(\"SID\", str.rstrip),\n",
    "            pdp.ApplyByCols(\"FILE_SPECIFICATION_NAME\", str.rstrip),\n",
    "            pdp.ColByFrameFunc(\n",
    "                \"START_TIME\",\n",
    "                lambda df: pandas.to_datetime(\n",
    "                    df[\"START_TIME\"], format=_index_time_format\n",
    "                ),\n",
    "            ),\n",
    "            pdp.ColByFrameFunc(\n",
    "                \"STOP_TIME\",\n",
    "                lambda df: pandas.to_datetime(\n",
    "                    df[\"STOP_TIME\"], format=_index_time_format\n",
    "                ),\n",
    "            ),\n",
    "            # pdp.ApplyByCols(['START_TIME', 'STOP_TIME'], pandas.to_datetime, format=_index_time_format), # NOTE: This is slow\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return jno_index_pipeline(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
